{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PetFinder.my Pawpularity Score / Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow Version: 2.6.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TensorFlow Strategy: _DefaultDistributionStrategy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Import utility libs\n",
    "import petfinder_pawpularity_config as config\n",
    "import petfinder_pawpularity_lib as mllib\n",
    "tf_strategy = mllib.tf_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable retina display\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "# Load Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Setting</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>env</td>\n",
       "      <td>local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mode</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debug</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_load_dir</td>\n",
       "      <td>models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_save_dir</td>\n",
       "      <td>models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset_dir_src</td>\n",
       "      <td>../input/petfinder-pawpularity-score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset_dir_cut</td>\n",
       "      <td>../input/petfinder-pawpularity-score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dataset_dir_copy</td>\n",
       "      <td>dataset-copy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dataset_batch_size</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dataset_image_size</td>\n",
       "      <td>(150, 150)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dataset_cut_ratio</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dataset_shrink_ratio</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dataset_split_ratios</td>\n",
       "      <td>[0.7, 0.2, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dataset_shuffle</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dataset_shuffle_seed</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dataset_prefetch</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train_save_checkpoint_flag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_fine_tuning_flag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train_load_model_flag</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>infer_load_model_flag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>synchronize_models_flag</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>train_max_epochs</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>train_early_stopping</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cleanup_data_flag</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Setting                                 Value\n",
       "0                          env                                 local\n",
       "1                      process                                 train\n",
       "2                         mode                                   cut\n",
       "3                        debug                                  True\n",
       "4               model_load_dir                                models\n",
       "5               model_save_dir                                models\n",
       "6              dataset_dir_src  ../input/petfinder-pawpularity-score\n",
       "7              dataset_dir_cut  ../input/petfinder-pawpularity-score\n",
       "8             dataset_dir_copy                          dataset-copy\n",
       "9           dataset_batch_size                                    64\n",
       "10          dataset_image_size                            (150, 150)\n",
       "11           dataset_cut_ratio                                   0.2\n",
       "12        dataset_shrink_ratio                                   1.0\n",
       "13        dataset_split_ratios                       [0.7, 0.2, 0.1]\n",
       "14             dataset_shuffle                                 False\n",
       "15        dataset_shuffle_seed                                    42\n",
       "16            dataset_prefetch                                    -1\n",
       "17  train_save_checkpoint_flag                                 False\n",
       "18      train_fine_tuning_flag                                 False\n",
       "19       train_load_model_flag                                  True\n",
       "20       infer_load_model_flag                                 False\n",
       "21     synchronize_models_flag                                  True\n",
       "22            train_max_epochs                                    10\n",
       "23        train_early_stopping                                     3\n",
       "24           cleanup_data_flag                                 False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Settings\n",
    "settings, debug = config.get_settings(\n",
    "    process=\"train\",\n",
    "    fallback_mode=\"full\"\n",
    ")\n",
    "mllib.show_dict(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cut training data\n",
    "dataset_dir = mllib.cut_training_data(\n",
    "    cut_ratio=settings[\"dataset_cut_ratio\"], \n",
    "    dataset_dir_src=settings[\"dataset_dir_src\"], \n",
    "    dataset_dir_cut=settings[\"dataset_dir_cut\"]\n",
    ")\n",
    "display(dataset_dir)\n",
    "\n",
    "# Copy train.csv to output (It may be different with submission dataset)\n",
    "if settings[\"dataset_dir_copy\"] is not None:\n",
    "    mllib.copy_file(os.path.join(dataset_dir, \"train.csv\"), os.path.join(settings[\"dataset_dir_copy\"], \"train%s.csv\" % mllib.cut_suffix(settings[\"dataset_cut_ratio\"])))\n",
    "\n",
    "# Train data\n",
    "training_data = mllib.load_training_data(dataset_dir)\n",
    "if debug: \n",
    "    display(training_data)\n",
    "    training_data.hist(bins=500, figsize=(18,3))\n",
    "\n",
    "# Make training data\n",
    "map_image_score_fn = lambda image, features, score, file_id: (image, score)  \n",
    "train_dataset, validate_dataset, test_dataset = mllib.make_training_validate_test_data(\n",
    "    dataset=mllib.load_training_dataset(\n",
    "        dataset_dir=dataset_dir,\n",
    "        mapping_data=training_data,\n",
    "        batch_size=settings[\"dataset_batch_size\"],\n",
    "        shuffle=settings[\"dataset_shuffle\"],\n",
    "        seed=settings[\"dataset_shuffle_seed\"],\n",
    "        image_size=settings[\"dataset_image_size\"],\n",
    "    ),\n",
    "    split_ratios=settings[\"dataset_split_ratios\"],\n",
    "    shrink_ratio=settings[\"dataset_shrink_ratio\"],\n",
    "    prefetch=settings[\"dataset_prefetch\"],\n",
    ")\n",
    " \n",
    "# Training data infos\n",
    "print(\"Train / Validate / Test datasets items: %s / %s / %s\" % (\n",
    "    settings[\"dataset_batch_size\"] * train_dataset().cardinality().numpy(), \n",
    "    settings[\"dataset_batch_size\"] * validate_dataset().cardinality().numpy(), \n",
    "    settings[\"dataset_batch_size\"] * test_dataset().cardinality().numpy()\n",
    "))\n",
    "if debug:\n",
    "    print(\"\")\n",
    "    print(\"Train dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(train_dataset().take(1).map(map_image_score_fn))\n",
    "    print(\"Validate dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(validate_dataset().take(1).map(map_image_score_fn))\n",
    "    print(\"Test dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(test_dataset().take(1).map(map_image_score_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Synchronize models from load to save directories\n",
    "if settings[\"synchronize_models_flag\"]:\n",
    "    synchronized_models = mllib.synchronize_models(\n",
    "        model_load_dir=settings[\"model_load_dir\"], \n",
    "        model_save_dir=settings[\"model_save_dir\"]\n",
    "    )\n",
    "    display(synchronized_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model parameters\n",
    "def get_model_parameters(settings):\n",
    "    dataset_image_size = settings[\"dataset_image_size\"]\n",
    "    model_parameters = {\n",
    "        \"model_prefix\": \"model\" + mllib.cut_suffix(settings[\"dataset_cut_ratio\"]),\n",
    "        \"model_base\": \"xception\",\n",
    "        \"input_shape\": [dataset_image_size[0], dataset_image_size[1], 3],\n",
    "        \"input_shape_features\": len(mllib.feature_fields),\n",
    "        \"output_size\": 1,\n",
    "        \"dropout_rate\": 0.3,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"dense_layers\": \"100\",\n",
    "        \"dense_layers_activation\": \"elu\",\n",
    "        \"early_stopping_patience\": settings[\"train_early_stopping\"],\n",
    "        \"save_checkpoint\": settings[\"train_save_checkpoint_flag\"],\n",
    "        \"epoch\": settings[\"train_max_epochs\"],\n",
    "        \"fine_tuning\": settings[\"train_fine_tuning_flag\"],\n",
    "    }\n",
    "    model_name = mllib.get_model_name(model_parameters)\n",
    "    model_file = mllib.model_file_path_load(model_name, settings[\"model_load_dir\"])\n",
    "    preload_weights = None if settings[\"train_load_model_flag\"] and os.path.exists(model_file) else \"imagenet\"\n",
    "    model_parameters[\"model_name\"] = model_name\n",
    "    model_parameters[\"preload_weights\"] = preload_weights\n",
    "    return model_parameters\n",
    "    \n",
    "model_parameters = get_model_parameters(settings)\n",
    "display(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train and evaluate model\n",
    "with tf_strategy.scope():\n",
    "    model = mllib.setup_model(model_parameters)\n",
    "    if debug:\n",
    "        mllib.show_model(model, settings[\"model_save_dir\"])\n",
    "    model_file = mllib.load_model(model, settings[\"model_load_dir\"])\n",
    "    print(\"Loaded Weights: %s\" % model_file)\n",
    "    history = mllib.train_model(\n",
    "        model=model, \n",
    "        train_dataset=train_dataset(),\n",
    "        validate_dataset=validate_dataset(), \n",
    "        parameters=model_parameters\n",
    "    )\n",
    "    mllib.describe_training(history)\n",
    "    if not settings[\"train_save_checkpoint_flag\"]:\n",
    "        model_file = mllib.save_model(model, settings[\"model_save_dir\"])\n",
    "        print(\"Saved Weights:\", model_file)\n",
    "    print(\"Evaluate:\")\n",
    "    evaluation = mllib.evaluate_model(model, test_dataset())\n",
    "    recorded_training_data = mllib.record_training_evaluate(\n",
    "        model_name=model.name,\n",
    "        model_file=model_file, \n",
    "        model_parameters=\"%s\" % model_parameters, \n",
    "        history=history, \n",
    "        evaluation=evaluation,\n",
    "        model_load_dir=settings[\"model_load_dir\"],\n",
    "        model_save_dir=settings[\"model_save_dir\"],\n",
    "        records_file=\"_train_logs.csv\",\n",
    "    )\n",
    "    display(recorded_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if settings[\"cleanup_data_flag\"]: \n",
    "    mllib.delete_training_data(cut_ratio=settings[\"dataset_cut_ratio\"], dataset_dir_cut=settings[\"dataset_dir_cut\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42794b777d0c0a3b1c381fbde1ad75bd986c804453608c824bcff673de9f39ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
