{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PetFinder.my Pawpularity Score / Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow Version: 2.6.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TensorFlow Strategy: _DefaultDistributionStrategy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Import landmark recognition lib\n",
    "import petfinder_pawpularity_lib as mllib\n",
    "tf_strategy = mllib.tf_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable retina display\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "# Load Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings Map\n",
    "if \"settingsMap\" not in globals(): settingsMap = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-local-cut\n",
    "settingsMap[\"train-local-cut\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 32,\n",
    "    \"dataset_image_size\": (250, 250),\n",
    "    \"dataset_cut_ratio\": 0.2,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.2, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"train_max_epochs\": 1,\n",
    "    \"train_early_stopping\": 3,\n",
    "    \"cleanup_data_flag\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-local-cut\n",
    "settingsMap[\"train-local-full\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (150, 150),\n",
    "    \"dataset_cut_ratio\": 1.0,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.2, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"train_max_epochs\": 5,\n",
    "    \"train_early_stopping\": 3,\n",
    "    \"cleanup_data_flag\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-remote-cut\n",
    "settingsMap[\"train-remote-cut\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-train\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (150, 150),\n",
    "    \"dataset_cut_ratio\": 0.2,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.2, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"train_max_epochs\": 10,\n",
    "    \"train_early_stopping\": 2,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-remote-full\n",
    "settingsMap[\"train-remote-full\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-train\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (150, 150),\n",
    "    \"dataset_cut_ratio\": 1.0,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.90, 0.05, 0.05],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"train_max_epochs\": 1,\n",
    "    \"train_early_stopping\": 2,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode\n",
    "mode = \"train-local-cut\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'debug': False,\n",
       " 'model_load_dir': 'models',\n",
       " 'model_save_dir': 'models',\n",
       " 'dataset_dir_src': '../input/petfinder-pawpularity-score',\n",
       " 'dataset_dir_cut': '../input/petfinder-pawpularity-score',\n",
       " 'dataset_dir_copy': 'dataset-copy',\n",
       " 'dataset_batch_size': 32,\n",
       " 'dataset_image_size': (250, 250),\n",
       " 'dataset_cut_ratio': 0.2,\n",
       " 'dataset_shrink_ratio': 1.0,\n",
       " 'dataset_split_ratios': [0.7, 0.2, 0.1],\n",
       " 'dataset_shuffle': False,\n",
       " 'dataset_shuffle_seed': None,\n",
       " 'dataset_prefetch': -1,\n",
       " 'train_save_checkpoint_flag': False,\n",
       " 'train_load_model_flag': True,\n",
       " 'infer_load_model_flag': False,\n",
       " 'train_max_epochs': 1,\n",
       " 'train_early_stopping': 3,\n",
       " 'cleanup_data_flag': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selected settings\n",
    "settings = settingsMap[mode]\n",
    "display(settings)\n",
    "\n",
    "# Debug\n",
    "debug = settings[\"debug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/petfinder-pawpularity-score-cut-0.200'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Copy ../input/petfinder-pawpularity-score-cut-0.200/train.csv to dataset-copy/train-cut-0.200.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Load training data from ../input/petfinder-pawpularity-score-cut-0.200/train.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7ff640644700> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ff640644700>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7ff640644700> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ff640644700>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Train / Validate / Test datasets items: 1376 / 384 / 192\n",
      "CPU times: user 897 ms, sys: 200 ms, total: 1.1 s\n",
      "Wall time: 946 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Cut training data\n",
    "dataset_dir = mllib.cut_training_data(\n",
    "    cut_ratio=settings[\"dataset_cut_ratio\"], \n",
    "    dataset_dir_src=settings[\"dataset_dir_src\"], \n",
    "    dataset_dir_cut=settings[\"dataset_dir_cut\"]\n",
    ")\n",
    "display(dataset_dir)\n",
    "\n",
    "# Copy train.csv to output (It may be different with submission dataset)\n",
    "if settings[\"dataset_dir_copy\"] is not None:\n",
    "    mllib.copy_file(os.path.join(dataset_dir, \"train.csv\"), os.path.join(settings[\"dataset_dir_copy\"], \"train%s.csv\" % mllib.cut_suffix(settings[\"dataset_cut_ratio\"])))\n",
    "\n",
    "# Train data\n",
    "training_data = mllib.load_training_data(dataset_dir)\n",
    "if debug: \n",
    "    display(training_data)\n",
    "    training_data.hist(bins=500, figsize=(18,3))\n",
    "\n",
    "# Make training data\n",
    "train_dataset, validate_dataset, test_dataset = mllib.make_training_validate_test_data(\n",
    "    dataset=mllib.load_training_dataset(\n",
    "        dataset_dir=dataset_dir,\n",
    "        mapping_data=training_data,\n",
    "        batch_size=settings[\"dataset_batch_size\"],\n",
    "        shuffle=settings[\"dataset_shuffle\"],\n",
    "        seed=settings[\"dataset_shuffle_seed\"],\n",
    "        image_size=settings[\"dataset_image_size\"],\n",
    "    ),\n",
    "    split_ratios=settings[\"dataset_split_ratios\"],\n",
    "    shrink_ratio=settings[\"dataset_shrink_ratio\"],\n",
    "    prefetch=settings[\"dataset_prefetch\"],\n",
    "    map_fn=lambda image, features, score, file_id: (image, score),\n",
    ")\n",
    "\n",
    "# Training data infos\n",
    "print(\"Train / Validate / Test datasets items: %s / %s / %s\" % (\n",
    "    settings[\"dataset_batch_size\"] * train_dataset().cardinality().numpy(), \n",
    "    settings[\"dataset_batch_size\"] * validate_dataset().cardinality().numpy(), \n",
    "    settings[\"dataset_batch_size\"] * test_dataset().cardinality().numpy()\n",
    "))\n",
    "if debug:\n",
    "    print(\"\")\n",
    "    print(\"Train dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(train_dataset().take(1))\n",
    "    print(\"Validate dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(validate_dataset().take(1))\n",
    "    print(\"Test dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(test_dataset().take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronize models from load to save directories\n",
    "mllib.synchronize_models(\n",
    "    model_load_dir=settings[\"model_load_dir\"], \n",
    "    model_save_dir=settings[\"model_save_dir\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_prefix': 'model_2_xception-cut-0.200',\n",
       " 'input_shape': [250, 250, 3],\n",
       " 'output_size': 1,\n",
       " 'dropout_rate': 0.3,\n",
       " 'learning_rate': 0.0005,\n",
       " 'early_stopping_patience': 3,\n",
       " 'save_checkpoint': False,\n",
       " 'epoch': 1,\n",
       " 'model_name': 'model_2_xception-cut-0.200-input-250x250x3-dropout-0.300',\n",
       " 'preload_weights': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare model parameters\n",
    "def get_model_parameters(settings):\n",
    "    dataset_image_size = settings[\"dataset_image_size\"]\n",
    "    model_parameters = {\n",
    "        \"model_prefix\": \"model_2_xception\" + mllib.cut_suffix(settings[\"dataset_cut_ratio\"]),\n",
    "        \"input_shape\": [dataset_image_size[0], dataset_image_size[1], 3],\n",
    "        \"output_size\": 1,\n",
    "        \"dropout_rate\": 0.3,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"early_stopping_patience\": settings[\"train_early_stopping\"],\n",
    "        \"save_checkpoint\": settings[\"train_save_checkpoint_flag\"],\n",
    "        \"epoch\": settings[\"train_max_epochs\"],\n",
    "    }\n",
    "    model_name = mllib.get_model_name(model_parameters)\n",
    "    model_file = mllib.model_file_path_load(model_name, settings[\"model_load_dir\"])\n",
    "    preload_weights = None if settings[\"train_load_model_flag\"] and os.path.exists(model_file) else \"imagenet\"\n",
    "    model_parameters[\"model_name\"] = model_name\n",
    "    model_parameters[\"preload_weights\"] = preload_weights\n",
    "    return model_parameters\n",
    "    \n",
    "model_parameters = get_model_parameters(settings)\n",
    "display(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_xception-cut-0.200-input-250x250x3-dropout-0.300\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 250, 250, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 250, 250, 3)       0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 8, 8, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               204900    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 21,066,481\n",
      "Trainable params: 205,001\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "Loaded Weights: models/model_2_xception-cut-0.200-input-250x250x3-dropout-0.300.h5\n",
      " 6/43 [===>..........................] - ETA: 1:34 - loss: 251.2001 - rmse: 15.8493"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train and evaluate model\n",
    "with tf_strategy.scope():\n",
    "    model = mllib.setup_model(model_parameters)\n",
    "    model_file = mllib.load_model(model, settings[\"model_load_dir\"])\n",
    "    print(\"Loaded Weights: %s\" % model_file)\n",
    "    history = mllib.train_model(\n",
    "        model=model, \n",
    "        train_dataset=train_dataset(),\n",
    "        validate_dataset=validate_dataset(), \n",
    "        parameters=model_parameters\n",
    "    )\n",
    "    mllib.describe_training(history)\n",
    "    if not settings[\"train_save_checkpoint_flag\"]:\n",
    "        model_file = mllib.save_model(model, settings[\"model_save_dir\"])\n",
    "        print(\"Saved Weights:\", model_file)\n",
    "    print(\"Evaluate:\")\n",
    "    evaluation = mllib.evaluate_model(model, test_dataset())\n",
    "    recorded_training_data = mllib.record_training_evaluate(\n",
    "        model_name=model.name,\n",
    "        model_file=model_file, \n",
    "        model_parameters=\"%s\" % model_parameters, \n",
    "        history=history, \n",
    "        evaluation=evaluation,\n",
    "        model_load_dir=settings[\"model_load_dir\"],\n",
    "        model_save_dir=settings[\"model_save_dir\"],\n",
    "        records_file=\"_train_logs.csv\",\n",
    "    )\n",
    "    display(recorded_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if settings[\"cleanup_data_flag\"]: \n",
    "    mllib.delete_training_data(cut_ratio=settings[\"dataset_cut_ratio\"], dataset_dir_cut=settings[\"dataset_dir_cut\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42794b777d0c0a3b1c381fbde1ad75bd986c804453608c824bcff673de9f39ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
