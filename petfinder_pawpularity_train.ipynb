{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PetFinder.my Pawpularity Score / Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow Version: 2.6.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TensorFlow Strategy: _DefaultDistributionStrategy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Import landmark recognition lib\n",
    "import petfinder_pawpularity_lib as mllib\n",
    "tf_strategy = mllib.tf_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable retina display\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "# Load Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings Map\n",
    "if \"settingsMap\" not in globals(): settingsMap = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-local-cut\n",
    "settingsMap[\"train-local-cut\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 32,\n",
    "    \"dataset_image_size\": (150, 150),\n",
    "    \"dataset_cut_ratio\": 0.2,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.2, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_fine_tuning_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"synchronize_models_flag\": True,\n",
    "    \"train_max_epochs\": 10,\n",
    "    \"train_early_stopping\": 3,\n",
    "    \"cleanup_data_flag\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-local-cut\n",
    "settingsMap[\"train-local-full\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (150, 150),\n",
    "    \"dataset_cut_ratio\": 1.0,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.2, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_fine_tuning_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"synchronize_models_flag\": True,\n",
    "    \"train_max_epochs\": 1,\n",
    "    \"train_early_stopping\": 3,\n",
    "    \"cleanup_data_flag\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-remote-cut\n",
    "settingsMap[\"train-remote-cut\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-train\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (500, 500),\n",
    "    \"dataset_cut_ratio\": 0.2,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.2, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_fine_tuning_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"synchronize_models_flag\": True,\n",
    "    \"train_max_epochs\": 10,\n",
    "    \"train_early_stopping\": 2,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-remote-full\n",
    "settingsMap[\"train-remote-full\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-train\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (500, 500),\n",
    "    \"dataset_cut_ratio\": 1.0,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.90, 0.05, 0.05],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_fine_tuning_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"synchronize_models_flag\": True,\n",
    "    \"train_max_epochs\": 1,\n",
    "    \"train_early_stopping\": 2,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-remote-full-empty\n",
    "settingsMap[\"train-remote-full-empty\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-empty\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_copy\": os.path.join(\"dataset-copy\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (500, 500),\n",
    "    \"dataset_cut_ratio\": 1.0,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.90, 0.05, 0.05],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": np.random.seed(42),\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"train_save_checkpoint_flag\": False,\n",
    "    \"train_fine_tuning_flag\": False,\n",
    "    \"train_load_model_flag\": True,\n",
    "    \"infer_load_model_flag\": False,\n",
    "    \"synchronize_models_flag\": True,\n",
    "    \"train_max_epochs\": 1,\n",
    "    \"train_early_stopping\": 3,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode\n",
    "mode = \"train-local-full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'debug': False,\n",
       " 'model_load_dir': 'models',\n",
       " 'model_save_dir': 'models',\n",
       " 'dataset_dir_src': '../input/petfinder-pawpularity-score',\n",
       " 'dataset_dir_cut': '../input/petfinder-pawpularity-score',\n",
       " 'dataset_dir_copy': 'dataset-copy',\n",
       " 'dataset_batch_size': 64,\n",
       " 'dataset_image_size': (150, 150),\n",
       " 'dataset_cut_ratio': 1.0,\n",
       " 'dataset_shrink_ratio': 1.0,\n",
       " 'dataset_split_ratios': [0.7, 0.2, 0.1],\n",
       " 'dataset_shuffle': False,\n",
       " 'dataset_shuffle_seed': None,\n",
       " 'dataset_prefetch': -1,\n",
       " 'train_save_checkpoint_flag': False,\n",
       " 'train_fine_tuning_flag': False,\n",
       " 'train_load_model_flag': True,\n",
       " 'infer_load_model_flag': False,\n",
       " 'synchronize_models_flag': True,\n",
       " 'train_max_epochs': 1,\n",
       " 'train_early_stopping': 3,\n",
       " 'cleanup_data_flag': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selected settings\n",
    "settings = settingsMap[mode]\n",
    "display(settings)\n",
    "\n",
    "# Debug\n",
    "debug = settings[\"debug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/petfinder-pawpularity-score'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Copy ../input/petfinder-pawpularity-score/train.csv to dataset-copy/train.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Load training data from ../input/petfinder-pawpularity-score/train.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train / Validate / Test datasets items: 6912 / 1984 / 960\n",
      "CPU times: user 1.72 s, sys: 901 ms, total: 2.62 s\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Cut training data\n",
    "dataset_dir = mllib.cut_training_data(\n",
    "    cut_ratio=settings[\"dataset_cut_ratio\"], \n",
    "    dataset_dir_src=settings[\"dataset_dir_src\"], \n",
    "    dataset_dir_cut=settings[\"dataset_dir_cut\"]\n",
    ")\n",
    "display(dataset_dir)\n",
    "\n",
    "# Copy train.csv to output (It may be different with submission dataset)\n",
    "if settings[\"dataset_dir_copy\"] is not None:\n",
    "    mllib.copy_file(os.path.join(dataset_dir, \"train.csv\"), os.path.join(settings[\"dataset_dir_copy\"], \"train%s.csv\" % mllib.cut_suffix(settings[\"dataset_cut_ratio\"])))\n",
    "\n",
    "# Train data\n",
    "training_data = mllib.load_training_data(dataset_dir)\n",
    "if debug: \n",
    "    display(training_data)\n",
    "    training_data.hist(bins=500, figsize=(18,3))\n",
    "\n",
    "# Make training data\n",
    "map_image_score_fn = lambda image, features, score, file_id: (image, score)  \n",
    "train_dataset, validate_dataset, test_dataset = mllib.make_training_validate_test_data(\n",
    "    dataset=mllib.load_training_dataset(\n",
    "        dataset_dir=dataset_dir,\n",
    "        mapping_data=training_data,\n",
    "        batch_size=settings[\"dataset_batch_size\"],\n",
    "        shuffle=settings[\"dataset_shuffle\"],\n",
    "        seed=settings[\"dataset_shuffle_seed\"],\n",
    "        image_size=settings[\"dataset_image_size\"],\n",
    "    ),\n",
    "    split_ratios=settings[\"dataset_split_ratios\"],\n",
    "    shrink_ratio=settings[\"dataset_shrink_ratio\"],\n",
    "    prefetch=settings[\"dataset_prefetch\"],\n",
    ")\n",
    " \n",
    "# Training data infos\n",
    "print(\"Train / Validate / Test datasets items: %s / %s / %s\" % (\n",
    "    settings[\"dataset_batch_size\"] * train_dataset().cardinality().numpy(), \n",
    "    settings[\"dataset_batch_size\"] * validate_dataset().cardinality().numpy(), \n",
    "    settings[\"dataset_batch_size\"] * test_dataset().cardinality().numpy()\n",
    "))\n",
    "if debug:\n",
    "    print(\"\")\n",
    "    print(\"Train dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(train_dataset().take(1).map(map_image_score_fn))\n",
    "    print(\"Validate dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(validate_dataset().take(1).map(map_image_score_fn))\n",
    "    print(\"Test dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(test_dataset().take(1).map(map_image_score_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.96 ms, sys: 1.66 ms, total: 3.62 ms\n",
      "Wall time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Synchronize models from load to save directories\n",
    "if settings[\"synchronize_models_flag\"]:\n",
    "    synchronized_models = mllib.synchronize_models(\n",
    "        model_load_dir=settings[\"model_load_dir\"], \n",
    "        model_save_dir=settings[\"model_save_dir\"]\n",
    "    )\n",
    "    display(synchronized_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_prefix': 'model',\n",
       " 'model_base': 'xception',\n",
       " 'input_shape': [150, 150, 3],\n",
       " 'input_shape_features': 12,\n",
       " 'output_size': 1,\n",
       " 'dropout_rate': 0.3,\n",
       " 'learning_rate': 0.0005,\n",
       " 'dense_layers': '100',\n",
       " 'early_stopping_patience': 3,\n",
       " 'save_checkpoint': False,\n",
       " 'epoch': 1,\n",
       " 'fine_tuning': False,\n",
       " 'model_name': 'model-xception-input-150x150x3-dense-100-dropout-0.300',\n",
       " 'preload_weights': 'imagenet'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare model parameters\n",
    "def get_model_parameters(settings):\n",
    "    dataset_image_size = settings[\"dataset_image_size\"]\n",
    "    model_parameters = {\n",
    "        \"model_prefix\": \"model\" + mllib.cut_suffix(settings[\"dataset_cut_ratio\"]),\n",
    "        \"model_base\": \"xception\",\n",
    "        \"input_shape\": [dataset_image_size[0], dataset_image_size[1], 3],\n",
    "        \"input_shape_features\": len(mllib.feature_fields),\n",
    "        \"output_size\": 1,\n",
    "        \"dropout_rate\": 0.3,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"dense_layers\": \"100\",\n",
    "        \"early_stopping_patience\": settings[\"train_early_stopping\"],\n",
    "        \"save_checkpoint\": settings[\"train_save_checkpoint_flag\"],\n",
    "        \"epoch\": settings[\"train_max_epochs\"],\n",
    "        \"fine_tuning\": settings[\"train_fine_tuning_flag\"],\n",
    "    }\n",
    "    model_name = mllib.get_model_name(model_parameters)\n",
    "    model_file = mllib.model_file_path_load(model_name, settings[\"model_load_dir\"])\n",
    "    preload_weights = None if settings[\"train_load_model_flag\"] and os.path.exists(model_file) else \"imagenet\"\n",
    "    model_parameters[\"model_name\"] = model_name\n",
    "    model_parameters[\"preload_weights\"] = preload_weights\n",
    "    return model_parameters\n",
    "    \n",
    "model_parameters = get_model_parameters(settings)\n",
    "display(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-xception-input-150x150x3-dense-100-dropout-0.300\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (None, 150, 150, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 150, 150, 3)  0           tf.math.truediv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Functional)           (None, 5, 5, 2048)   20861480    tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_features (InputLayer)     [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2060)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 input_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1_r0.300 (Dropout)      (None, 2060)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          206100      dropout_1_r0.300[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,067,681\n",
      "Trainable params: 206,201\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n",
      "Loaded Weights: None\n",
      "108/108 [==============================] - 339s 3s/step - loss: 526.5087 - rmse: 22.9458 - val_loss: 427.7573 - val_rmse: 20.6823\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Weights: models/model-xception-input-150x150x3-dense-100-dropout-0.300.h5\n",
      "Evaluate:\n",
      "15/15 [==============================] - 27s 2s/step - loss: 422.3974 - rmse: 20.5523\n",
      "Successfully written training records to models/_train_logs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_parameters</th>\n",
       "      <th>iteration</th>\n",
       "      <th>epochs</th>\n",
       "      <th>epochs_sum</th>\n",
       "      <th>steps</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>trained_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1-cut-0.200-input-150x150x3-dense-512x25...</td>\n",
       "      <td>{'model_base': 'xception', 'model_prefix': 'mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>25.002</td>\n",
       "      <td>21.892</td>\n",
       "      <td>21.573</td>\n",
       "      <td>2021-10-24 21:29:36.035893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_1-cut-0.200-input-150x150x3-dense-512x25...</td>\n",
       "      <td>{'model_base': 'xception', 'model_prefix': 'mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>24.549</td>\n",
       "      <td>21.795</td>\n",
       "      <td>20.895</td>\n",
       "      <td>2021-10-25 11:08:23.950308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_1-cut-0.200-input-150x150x3-dense-512x25...</td>\n",
       "      <td>{'model_base': 'xception', 'model_prefix': 'mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>22.287</td>\n",
       "      <td>21.456</td>\n",
       "      <td>21.052</td>\n",
       "      <td>2021-10-25 12:09:49.816912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model--cut-0.200-efficientnetb7-input-150x150x...</td>\n",
       "      <td>{'model_prefix': 'model--cut-0.200', 'model_ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>25.896</td>\n",
       "      <td>21.448</td>\n",
       "      <td>20.551</td>\n",
       "      <td>2021-10-26 15:50:12.529869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model-cut-0.200-efficientnetb7-input-150x150x3...</td>\n",
       "      <td>{'model_prefix': 'model-cut-0.200', 'model_bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>20.498</td>\n",
       "      <td>20.751</td>\n",
       "      <td>19.956</td>\n",
       "      <td>2021-10-26 21:47:51.996906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model-cut-0.200-efficientnetb7-input-150x150x3...</td>\n",
       "      <td>{'model_prefix': 'model-cut-0.200', 'model_bas...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>18.205</td>\n",
       "      <td>21.098</td>\n",
       "      <td>20.047</td>\n",
       "      <td>2021-10-26 22:01:05.561140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model-efficientnetb7-input-150x150x3-dense-512...</td>\n",
       "      <td>{'model_prefix': 'model', 'model_base': 'effic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>22.429</td>\n",
       "      <td>19.456</td>\n",
       "      <td>19.808</td>\n",
       "      <td>2021-10-26 22:18:56.801677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model-efficientnetb7-input-150x150x3-dense-512...</td>\n",
       "      <td>{'model_prefix': 'model', 'model_base': 'effic...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>19.851</td>\n",
       "      <td>19.305</td>\n",
       "      <td>19.345</td>\n",
       "      <td>2021-10-26 22:51:14.648632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model-efficientnetb7-input-150x150x3-dense-512...</td>\n",
       "      <td>{'model_prefix': 'model', 'model_base': 'effic...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>19.697</td>\n",
       "      <td>19.321</td>\n",
       "      <td>19.256</td>\n",
       "      <td>2021-10-26 23:12:54.816938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model-efficientnetb7-input-150x150x3-dense-512...</td>\n",
       "      <td>{'model_prefix': 'model', 'model_base': 'effic...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>19.506</td>\n",
       "      <td>19.426</td>\n",
       "      <td>19.368</td>\n",
       "      <td>2021-10-26 23:28:41.634917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model-efficientnetb7-input-150x150x3-dense-512...</td>\n",
       "      <td>{'model_prefix': 'model', 'model_base': 'effic...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>19.397</td>\n",
       "      <td>19.426</td>\n",
       "      <td>19.322</td>\n",
       "      <td>2021-10-27 07:15:02.657103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model-efficientnetb7-input-150x150x3-dense-512...</td>\n",
       "      <td>{'model_prefix': 'model', 'model_base': 'effic...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>19.342</td>\n",
       "      <td>19.359</td>\n",
       "      <td>19.352</td>\n",
       "      <td>2021-10-27 07:33:52.647564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model-efficientnetb7-input-150x150x3-dense-512...</td>\n",
       "      <td>{'model_prefix': 'model', 'model_base': 'effic...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>108</td>\n",
       "      <td>19.172</td>\n",
       "      <td>19.408</td>\n",
       "      <td>19.306</td>\n",
       "      <td>2021-10-27 07:56:24.526851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model-xception-input-150x150x3-dense-100-dropo...</td>\n",
       "      <td>{'model_prefix': 'model', 'model_base': 'xcept...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>22.946</td>\n",
       "      <td>20.682</td>\n",
       "      <td>20.552</td>\n",
       "      <td>2021-10-28 19:57:12.305789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name  \\\n",
       "0   model_1-cut-0.200-input-150x150x3-dense-512x25...   \n",
       "1   model_1-cut-0.200-input-150x150x3-dense-512x25...   \n",
       "2   model_1-cut-0.200-input-150x150x3-dense-512x25...   \n",
       "3   model--cut-0.200-efficientnetb7-input-150x150x...   \n",
       "4   model-cut-0.200-efficientnetb7-input-150x150x3...   \n",
       "5   model-cut-0.200-efficientnetb7-input-150x150x3...   \n",
       "6   model-efficientnetb7-input-150x150x3-dense-512...   \n",
       "7   model-efficientnetb7-input-150x150x3-dense-512...   \n",
       "8   model-efficientnetb7-input-150x150x3-dense-512...   \n",
       "9   model-efficientnetb7-input-150x150x3-dense-512...   \n",
       "10  model-efficientnetb7-input-150x150x3-dense-512...   \n",
       "11  model-efficientnetb7-input-150x150x3-dense-512...   \n",
       "12  model-efficientnetb7-input-150x150x3-dense-512...   \n",
       "13  model-xception-input-150x150x3-dense-100-dropo...   \n",
       "\n",
       "                                     model_parameters  iteration  epochs  \\\n",
       "0   {'model_base': 'xception', 'model_prefix': 'mo...          1       1   \n",
       "1   {'model_base': 'xception', 'model_prefix': 'mo...          1       1   \n",
       "2   {'model_base': 'xception', 'model_prefix': 'mo...          2       1   \n",
       "3   {'model_prefix': 'model--cut-0.200', 'model_ba...          1       1   \n",
       "4   {'model_prefix': 'model-cut-0.200', 'model_bas...          1       1   \n",
       "5   {'model_prefix': 'model-cut-0.200', 'model_bas...          2      10   \n",
       "6   {'model_prefix': 'model', 'model_base': 'effic...          1       1   \n",
       "7   {'model_prefix': 'model', 'model_base': 'effic...          2       1   \n",
       "8   {'model_prefix': 'model', 'model_base': 'effic...          3       1   \n",
       "9   {'model_prefix': 'model', 'model_base': 'effic...          4       1   \n",
       "10  {'model_prefix': 'model', 'model_base': 'effic...          5       1   \n",
       "11  {'model_prefix': 'model', 'model_base': 'effic...          6       1   \n",
       "12  {'model_prefix': 'model', 'model_base': 'effic...          7       1   \n",
       "13  {'model_prefix': 'model', 'model_base': 'xcept...          1       1   \n",
       "\n",
       "    epochs_sum  steps train_rmse val_rmse test_rmse  \\\n",
       "0            1     43     25.002   21.892    21.573   \n",
       "1            1     43     24.549   21.795    20.895   \n",
       "2            2     43     22.287   21.456    21.052   \n",
       "3            1     43     25.896   21.448    20.551   \n",
       "4            1     43     20.498   20.751    19.956   \n",
       "5           11     43     18.205   21.098    20.047   \n",
       "6            1    108     22.429   19.456    19.808   \n",
       "7            2    108     19.851   19.305    19.345   \n",
       "8            3    108     19.697   19.321    19.256   \n",
       "9            4    108     19.506   19.426    19.368   \n",
       "10           5    108     19.397   19.426    19.322   \n",
       "11           6    108     19.342   19.359    19.352   \n",
       "12           7    108     19.172   19.408    19.306   \n",
       "13           1    108     22.946   20.682    20.552   \n",
       "\n",
       "                    trained_at  \n",
       "0   2021-10-24 21:29:36.035893  \n",
       "1   2021-10-25 11:08:23.950308  \n",
       "2   2021-10-25 12:09:49.816912  \n",
       "3   2021-10-26 15:50:12.529869  \n",
       "4   2021-10-26 21:47:51.996906  \n",
       "5   2021-10-26 22:01:05.561140  \n",
       "6   2021-10-26 22:18:56.801677  \n",
       "7   2021-10-26 22:51:14.648632  \n",
       "8   2021-10-26 23:12:54.816938  \n",
       "9   2021-10-26 23:28:41.634917  \n",
       "10  2021-10-27 07:15:02.657103  \n",
       "11  2021-10-27 07:33:52.647564  \n",
       "12  2021-10-27 07:56:24.526851  \n",
       "13  2021-10-28 19:57:12.305789  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 29s, sys: 4min 16s, total: 28min 46s\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train and evaluate model\n",
    "with tf_strategy.scope():\n",
    "    model = mllib.setup_model(model_parameters)\n",
    "    if debug:\n",
    "        mllib.show_model(model, settings[\"model_save_dir\"])\n",
    "    model_file = mllib.load_model(model, settings[\"model_load_dir\"])\n",
    "    print(\"Loaded Weights: %s\" % model_file)\n",
    "    history = mllib.train_model(\n",
    "        model=model, \n",
    "        train_dataset=train_dataset(),\n",
    "        validate_dataset=validate_dataset(), \n",
    "        parameters=model_parameters\n",
    "    )\n",
    "    mllib.describe_training(history)\n",
    "    if not settings[\"train_save_checkpoint_flag\"]:\n",
    "        model_file = mllib.save_model(model, settings[\"model_save_dir\"])\n",
    "        print(\"Saved Weights:\", model_file)\n",
    "    print(\"Evaluate:\")\n",
    "    evaluation = mllib.evaluate_model(model, test_dataset())\n",
    "    recorded_training_data = mllib.record_training_evaluate(\n",
    "        model_name=model.name,\n",
    "        model_file=model_file, \n",
    "        model_parameters=\"%s\" % model_parameters, \n",
    "        history=history, \n",
    "        evaluation=evaluation,\n",
    "        model_load_dir=settings[\"model_load_dir\"],\n",
    "        model_save_dir=settings[\"model_save_dir\"],\n",
    "        records_file=\"_train_logs.csv\",\n",
    "    )\n",
    "    display(recorded_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if settings[\"cleanup_data_flag\"]: \n",
    "    mllib.delete_training_data(cut_ratio=settings[\"dataset_cut_ratio\"], dataset_dir_cut=settings[\"dataset_dir_cut\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42794b777d0c0a3b1c381fbde1ad75bd986c804453608c824bcff673de9f39ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
