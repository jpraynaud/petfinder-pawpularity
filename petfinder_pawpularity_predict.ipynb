{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PetFinder.my Pawpularity Score / Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow Version: 2.6.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'TensorFlow Strategy: _DefaultDistributionStrategy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Import landmark recognition lib\n",
    "import petfinder_pawpularity_lib as mllib\n",
    "tf_strategy = mllib.tf_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable retina display\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "# Load Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings Map\n",
    "if \"settingsMap\" not in globals(): settingsMap = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict-local-cut\n",
    "settingsMap[\"predict-local-cut\"] = {\n",
    "    \"debug\": True,\n",
    "    \"model_load_dir\": os.path.join(\"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_batch_size\": 16,\n",
    "    \"dataset_image_size\": (250, 250),\n",
    "    \"dataset_cut_ratio\": 0.2,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.20, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": 42,\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"score_sample_size\": 10,\n",
    "    \"cleanup_data_flag\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict-local-full\n",
    "settingsMap[\"predict-local-full\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (150, 150),\n",
    "    \"dataset_cut_ratio\": 1.0,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.2, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": 42,\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"score_sample_size\": 10,\n",
    "    \"cleanup_data_flag\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict-remote-model-cut\n",
    "settingsMap[\"predict-remote-model-cut\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-model\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (500, 500),\n",
    "    \"dataset_cut_ratio\": 0.2,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.20, 0.1],\n",
    "    \"dataset_shuffle\": False,\n",
    "    \"dataset_shuffle_seed\": 42,\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"score_sample_size\": 10,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict-remote-model-full\n",
    "settingsMap[\"predict-remote-model-full\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-model\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (750, 750),\n",
    "    \"dataset_cut_ratio\": 1.0,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.90, 0.05, 0.05],\n",
    "    \"dataset_shuffle\": True,\n",
    "    \"dataset_shuffle_seed\": 42,\n",
    "    \"dataset_prefetch\": 1,\n",
    "    \"score_sample_size\": 10,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict-remote-train-cut\n",
    "settingsMap[\"predict-remote-train-cut\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-train\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (500, 500),\n",
    "    \"dataset_cut_ratio\": 0.2,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.7, 0.20, 0.1],\n",
    "    \"dataset_shuffle\": True,\n",
    "    \"dataset_shuffle_seed\": 42,\n",
    "    \"dataset_prefetch\": mllib.tf.data.AUTOTUNE,\n",
    "    \"score_sample_size\": 10,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict-remote-train-full\n",
    "settingsMap[\"predict-remote-train-full\"] = {\n",
    "    \"debug\": False,\n",
    "    \"model_load_dir\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-train\", \"models\"),\n",
    "    \"model_save_dir\": os.path.join(\"models\"),\n",
    "    \"dataset_dir_src\": os.path.join(\"..\", \"input\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_dir_cut\": os.path.join(\"dataset\", \"petfinder-pawpularity-score\"),\n",
    "    \"dataset_batch_size\": 64,\n",
    "    \"dataset_image_size\": (750, 750),\n",
    "    \"dataset_cut_ratio\": 1.0,\n",
    "    \"dataset_shrink_ratio\": 1.0,\n",
    "    \"dataset_split_ratios\": [0.90, 0.05, 0.05],\n",
    "    \"dataset_shuffle\": True,\n",
    "    \"dataset_shuffle_seed\": 42,\n",
    "    \"dataset_prefetch\": 1,\n",
    "    \"score_sample_size\": 10,\n",
    "    \"cleanup_data_flag\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode\n",
    "mode = \"predict-local-full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'debug': False,\n",
       " 'model_load_dir': 'models',\n",
       " 'model_save_dir': 'models',\n",
       " 'dataset_dir_src': '../input/petfinder-pawpularity-score',\n",
       " 'dataset_dir_cut': '../input/petfinder-pawpularity-score',\n",
       " 'dataset_batch_size': 64,\n",
       " 'dataset_image_size': (150, 150),\n",
       " 'dataset_cut_ratio': 1.0,\n",
       " 'dataset_shrink_ratio': 1.0,\n",
       " 'dataset_split_ratios': [0.7, 0.2, 0.1],\n",
       " 'dataset_shuffle': False,\n",
       " 'dataset_shuffle_seed': 42,\n",
       " 'dataset_prefetch': -1,\n",
       " 'score_sample_size': 10,\n",
       " 'cleanup_data_flag': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selected settings\n",
    "settings = settingsMap[mode]\n",
    "display(settings)\n",
    "\n",
    "# Debug\n",
    "debug = settings[\"debug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/petfinder-pawpularity-score'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Load training data from ../input/petfinder-pawpularity-score/train.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train / Validate / Test datasets items: 6912 / 1984 / 960\n",
      "CPU times: user 1.88 s, sys: 907 ms, total: 2.78 s\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Cut training data\n",
    "dataset_dir = mllib.cut_training_data(\n",
    "    cut_ratio=settings[\"dataset_cut_ratio\"], \n",
    "    dataset_dir_src=settings[\"dataset_dir_src\"], \n",
    "    dataset_dir_cut=settings[\"dataset_dir_cut\"]\n",
    ")\n",
    "display(dataset_dir)\n",
    "\n",
    "# Train data\n",
    "training_data = mllib.load_training_data(dataset_dir)\n",
    "if debug: \n",
    "    display(training_data)\n",
    "    training_data.hist(bins=500, figsize=(18,3))\n",
    "\n",
    "# Make training data\n",
    "map_image_score_fn = lambda image, features, score, file_id: (image, score)  \n",
    "train_dataset, validate_dataset, test_dataset = mllib.make_training_validate_test_data(\n",
    "    dataset=mllib.load_training_dataset(\n",
    "        dataset_dir=dataset_dir,\n",
    "        mapping_data=training_data,\n",
    "        batch_size=settings[\"dataset_batch_size\"],\n",
    "        shuffle=settings[\"dataset_shuffle\"],\n",
    "        seed=settings[\"dataset_shuffle_seed\"],\n",
    "        image_size=settings[\"dataset_image_size\"],\n",
    "    ),\n",
    "    split_ratios=settings[\"dataset_split_ratios\"],\n",
    "    shrink_ratio=settings[\"dataset_shrink_ratio\"],\n",
    "    prefetch=settings[\"dataset_prefetch\"],\n",
    ")\n",
    "\n",
    "# Training data infos\n",
    "print(\"Train / Validate / Test datasets items: %s / %s / %s\" % (\n",
    "    settings[\"dataset_batch_size\"] * train_dataset().cardinality().numpy(), \n",
    "    settings[\"dataset_batch_size\"] * validate_dataset().cardinality().numpy(), \n",
    "    settings[\"dataset_batch_size\"] * test_dataset().cardinality().numpy()\n",
    "))\n",
    "if debug:\n",
    "    print(\"\")\n",
    "    print(\"Train dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(train_dataset().take(1).map(map_image_score_fn))\n",
    "    print(\"Validate dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(validate_dataset().take(1).map(map_image_score_fn))\n",
    "    print(\"Test dataset:\")\n",
    "    mllib.plot_images_scores_from_dataset(test_dataset().take(1).map(map_image_score_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_prefix': 'model',\n",
       " 'model_base': 'xception',\n",
       " 'input_shape': [150, 150, 3],\n",
       " 'input_shape_features': 12,\n",
       " 'output_size': 1,\n",
       " 'dropout_rate': 0.3,\n",
       " 'learning_rate': 0.0005,\n",
       " 'dense_layers': '100',\n",
       " 'dense_layers_activation': 'elu',\n",
       " 'preload_weights': None,\n",
       " 'model_name': 'model-xception-input-150x150x3-dense-100-dropout-0.300'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare model parameters\n",
    "def get_model_parameters(settings):\n",
    "    dataset_image_size = settings[\"dataset_image_size\"]\n",
    "    model_parameters = {\n",
    "        \"model_prefix\": \"model\" + mllib.cut_suffix(settings[\"dataset_cut_ratio\"]),\n",
    "        \"model_base\": \"xception\",\n",
    "        \"input_shape\": [dataset_image_size[0], dataset_image_size[1], 3],\n",
    "        \"input_shape_features\": len(mllib.feature_fields),\n",
    "        \"output_size\": 1,\n",
    "        \"dropout_rate\": 0.3,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"dense_layers\": \"100\",\n",
    "        \"dense_layers_activation\": \"elu\",\n",
    "        \"preload_weights\": None,\n",
    "    }\n",
    "    model_name = mllib.get_model_name(model_parameters)\n",
    "    model_parameters[\"model_name\"] = model_name\n",
    "    return model_parameters\n",
    "    \n",
    "model_parameters = get_model_parameters(settings)\n",
    "display(model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-xception-input-150x150x3-dense-100-dropout-0.300\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (None, 150, 150, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 150, 150, 3)  0           tf.math.truediv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Functional)           (None, 5, 5, 2048)   20861480    tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_main (Dense)              (None, 12)           24588       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "input_features (InputLayer)     [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 24)           0           dense_main[0][0]                 \n",
      "                                                                 input_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24)           96          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1_r0.300 (Dropout)      (None, 24)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          2500        dropout_1_r0.300[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 1)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,888,765\n",
      "Trainable params: 27,237\n",
      "Non-trainable params: 20,861,528\n",
      "__________________________________________________________________________________________________\n",
      "Loaded Weights: models/model-xception-input-150x150x3-dense-100-dropout-0.300.h5\n",
      "CPU times: user 1.93 s, sys: 314 ms, total: 2.25 s\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load model\n",
    "with tf_strategy.scope():\n",
    "    model = mllib.setup_model(model_parameters)\n",
    "    model_file = mllib.load_model(model, settings[\"model_load_dir\"])\n",
    "    print(\"Loaded Weights: %s\" % model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 2 µs, total: 6 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict on test dataset\n",
    "if debug:\n",
    "    with tf_strategy.scope():\n",
    "        images, features, scores, file_ids, *_ = mllib.load_images_scores_from_dataset(test_dataset().shuffle(100).take(1))\n",
    "        for index in range(len(images[:5])):\n",
    "            print(\"*** Test Image #\",index+1)\n",
    "            mllib.predict(\n",
    "                model=model, \n",
    "                image=images[index],\n",
    "                features=features[index],\n",
    "                label=file_ids[index],\n",
    "                true_score=scores[index], \n",
    "            )\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "'Train Submission RMSE Score [Samples=10]: 19.290502'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 20.7 s, total: 2min 8s\n",
      "Wall time: 34.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Score train submission data\n",
    "train_score, train_scored_data = mllib.score_submission_data(\n",
    "    submission_data=mllib.infer_submission_data(\n",
    "        dataset=train_dataset,\n",
    "        model=model, \n",
    "        take=settings[\"score_sample_size\"]\n",
    "    ), \n",
    "    training_data=training_data\n",
    ")\n",
    "display(\"Train Submission RMSE Score [Samples=%i]: %f\" % (settings[\"score_sample_size\"], train_score))\n",
    "if debug: display(train_scored_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "'Validate Submission RMSE Score [Samples=10]: 19.113076'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 19.8 s, total: 2min 4s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Score validate submission data\n",
    "validate_score, validate_scored_data = mllib.score_submission_data(\n",
    "    submission_data=mllib.infer_submission_data(\n",
    "        dataset=validate_dataset,\n",
    "        model=model, \n",
    "        take=settings[\"score_sample_size\"]\n",
    "    ), \n",
    "    training_data=training_data\n",
    ")\n",
    "display(\"Validate Submission RMSE Score [Samples=%i]: %f\" % (settings[\"score_sample_size\"], validate_score))\n",
    "if debug: display(validate_scored_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "'Test Submission RMSE Score [Samples=10]: 19.616197'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 42s, sys: 18.9 s, total: 2min 1s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Score test submission data\n",
    "test_score, test_scored_data = mllib.score_submission_data(\n",
    "    submission_data=mllib.infer_submission_data(\n",
    "        dataset=test_dataset,\n",
    "        model=model, \n",
    "        take=settings[\"score_sample_size\"]\n",
    "    ), \n",
    "    training_data=training_data\n",
    ")\n",
    "display(\"Test Submission RMSE Score [Samples=%i]: %f\" % (settings[\"score_sample_size\"], test_score))\n",
    "if debug: display(test_scored_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if settings[\"cleanup_data_flag\"]: \n",
    "    mllib.delete_training_data(cut_ratio=settings[\"dataset_cut_ratio\"], dataset_dir_cut=settings[\"dataset_dir_cut\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42794b777d0c0a3b1c381fbde1ad75bd986c804453608c824bcff673de9f39ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
